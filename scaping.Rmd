---
title: "Scraping Metacritic or: How I Learned to Stop Worrying and Love Loops"
output: html_notebook
---
The script works fine. I will do the rest of the data wrangling and write up the analysis later.

```{r}
library(tidyverse)
library(rvest)
library(lubridate)
library(tidytext)
```

```{r}
page_initial <- read_html("https://www.metacritic.com/browse/games/release-date/available/ps4/metascore?page=0")
no_pages <- page_initial %>% html_nodes(".page_num") %>% html_text()
```

```{r}
# Reading in pages and extracting hyperlinks
result <- vector("list", length(no_pages))

for(i in 0:(length(no_pages)-1)) {
  webpage <- read_html(paste0("https://www.metacritic.com/browse/games/release-date/available/ps4/metascore?page=", i))
  loop_links <- webpage %>% html_nodes("#main .product_title a") %>% html_attr('href')
  loop_links_proper <- paste0("https://www.metacritic.com", loop_links)
  result[[i+1]] <- loop_links_proper
}

# Joining results into a single vector
all_links <- unlist(result)
all_links_reviews <- paste0(all_links, "/critic-reviews")
```

```{r}
# Getting all the attributes
final_result <- vector("list", length(all_links))
names(final_result) <- all_links

# Set 0 for progress bar
no <- 0

for(i in all_links) {
  
# Start the trycatch
try({    

game_page <- read_html(i)

title <- game_page %>% html_nodes("h1") %>% html_text()
release_date <- game_page %>% html_nodes(".release_data .data") %>% html_text()
developer <- game_page %>% html_nodes(".developer .data") %>% html_text()
publisher <- game_page %>% html_nodes(".publisher a") %>% html_text()
genre <- game_page %>% html_nodes(".product_genre .data") %>% html_text()
score <- game_page %>% html_nodes(".positive span, .mixed span, .negative span") %>% html_text()
review_count <- game_page %>% html_nodes(".highlight_metascore .count a") %>% html_text()
description <- game_page %>% html_nodes(".product_summary .data span") %>% html_text()
description <- description[1]

# Checking if data is present, if empty, enter Notapplicable
title <- ifelse(length(title) == 0, "Notapplicable", title)
release_date <- ifelse(length(release_date) == 0, "Notapplicable", release_date)
developer <- ifelse(length(developer) == 0, "Notapplicable", developer)
publisher <- ifelse(length(publisher) == 0, "Notapplicable", publisher)
genre <- ifelse(length(genre) == 0, "Notapplicable", genre)
score <- ifelse(length(score) == 0, "Notapplicable", score)
review_count <- ifelse(length(review_count) == 0, "Notapplicable", review_count)
description <- ifelse(length(description) == 0, "Notapplicable", description)

genre <- paste(genre, collapse = ', ')

# Creating table entry from vectors
final_result[[i]] <- data.frame(title, release_date, developer, publisher, genre, score, review_count, description)

# End the trycatch
}, silent=TRUE)
# Progress bar
no <- no + 1
print(paste0("Progress: ", no, "/", length(all_links), ", ", round(no/length(all_links)*100, 2), "%"))
}
```

## Scraping all review scores

```{r}
critic_score_loop_output <- vector("list", length(all_links))
names(critic_score_loop_output) <- all_links_reviews
nos <- 0

for (i in all_links_reviews) {

try({ 
   
critic_page <- read_html(i)
critic_page_score <- critic_page %>% html_nodes("h1 , #main .indiv") %>% html_text()
critic_score_loop_output[[i]] <- critic_page_score

}, silent=TRUE)

nos <- nos + 1
print(paste0("Progress: ", nos, "/", length(all_links_reviews), ", ", round(nos/length(all_links_reviews)*100, 2), "%"))
}
```

```{r}
#dataset <- do.call("rbind", temp_results)
```

The script is not perfect as it truncates the genre to a single value, something to look out for. Also, the description is taken as a single scraped category, which leaves a lot of values empty. I'm fairly happy with this overall. Time to clean up the data.

696 of the 1607 games have missing descriptions, which is 43%. Not ideal but workable

```{r}
# dataset$title <- as.character(dataset$title)
# dataset$release_date <- as.character(dataset$release_date)
# dataset$release_date <- mdy(dataset$release_date)
# dataset$developer <- as.character(dataset$developer)
# dataset$publisher <- as.character(dataset$publisher)
# dataset$genre <- as.character(dataset$genre)
# dataset$score <- as.numeric(as.character(dataset$score))
# dataset$review_count <- as.character(dataset$review_count)
# dataset$review_count <- gsub(" Critics", "", dataset$review_count)
# dataset$review_count <- as.numeric(dataset$review_count)
# dataset$description <- as.character(dataset$description)
```

## Replacing for loop with a 'map' function

This is the only problem now. It's quite a big one actually as it prevents the pages from being scraped completely. The first 404 error stops the entire loop. I will use a map function to get around this. After this step the script can be assembled and the fun begins.


```{r}
# collapsible_game_page <- read_html("https://www.metacritic.com/game/playstation-4/wolfenstein-ii-the-new-colossus")
# collapsible_game_description <- collapsible_game_page %>% html_nodes(".product_summary .data span") %>% html_text()
```

```{r}
# collapsible_game_page <- read_html("https://www.metacritic.com/game/playstation-4/celeste")
# collapsible_game_description <- collapsible_game_page %>% html_nodes(".product_summary .data span") %>% html_text()
# test <- collapsible_game_description[1]
```


```{r}
# result <- 0
# for(i in 1:10){
#   try({                # start code block
#   result = result + i
#   log("a")             # I do not care about this error
#   result = result + i
#   }, silent=TRUE)      # end of try function
# }
```


